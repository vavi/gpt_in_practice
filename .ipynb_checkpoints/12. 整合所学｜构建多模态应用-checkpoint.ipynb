{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f2cfc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = \"gpt4\"\n",
    "model = \"gpt-4\"\n",
    "embedding_deployment=\"embedding\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b65ca7",
   "metadata": {},
   "source": [
    "# 回顾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0c2a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "# embedding = OpenAIEmbeddings() #如果直接访问OpenAI的 GPT服务 \n",
    "embedding = OpenAIEmbeddings(deployment=\"embedding\") #如果访问Azure的OpenAI的 GPT服务 \n",
    "persist_directory = 'data/'\n",
    "\n",
    "vectordb = Chroma(\n",
    "    collection_name=\"spotmax\",\n",
    "    embedding_function=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cf29e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79e3325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "# from langchain.chat_models import ChatOpenAI #直接访问OpenAI的GPT服务\n",
    "\n",
    "#llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0) #直接访问OpenAI的GPT服务\n",
    "llm = AzureChatOpenAI(deployment_name = deployment, model_name=model, temperature=0.7, max_tokens=1000) #通过Azure的OpenAI服务\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"map_reduce\", retriever=vectordb.as_retriever(),return_source_documents=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b281920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(input):\n",
    "    print(input)\n",
    "    result = qa({\"query\": input})\n",
    "    return result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "185c9384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "什么是MaxGroup？\n",
      "MaxGroup是根据服务工作模式和运行特征，优化主机群集的一种方式。它的智能弹性集群管理可以有效减少弹性计算资源波动（如：竞价实例的中断）带来的集群服务能力变化。并在面向成本优化构建的混合机型集群中，最大发挥集群不同机型的服务能力。\n"
     ]
    }
   ],
   "source": [
    "print(get_response(\"什么是MaxGroup？\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c68c71f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://84da37dc8fba5ab56e.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://84da37dc8fba5ab56e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "什么是SpotMax？\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "def respond(message, chat_history):\n",
    "    bot_message = get_response(message)\n",
    "    chat_history.append((message, bot_message))\n",
    "    return \"\", chat_history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(height=300) #just to fit the notebook\n",
    "    msg = gr.Textbox(label=\"Prompt\")\n",
    "    btn = gr.Button(\"Submit\")\n",
    "    clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "\n",
    "    btn.click(respond, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "    msg.submit(respond, inputs=[msg, chatbot], outputs=[msg, chatbot]) #Press enter to submit\n",
    "gr.close_all()\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae68e807",
   "metadata": {},
   "source": [
    "# 从文本到图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e076eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import http.client\n",
    "import requests\n",
    "import time\n",
    "\n",
    "def create_image(prompt):\n",
    "  api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "  api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "  api_version = api_version = '2022-08-03-preview'\n",
    "\n",
    "  url = \"{}dalle/text-to-image?api-version={}\".format(api_base, api_version)\n",
    "  headers= { \"api-key\": api_key, \"Content-Type\": \"application/json\" }\n",
    "  body = {\n",
    "      \"caption\": prompt,\n",
    "      \"resolution\": \"512x512\"\n",
    "  }\n",
    "  submission = requests.post(url, headers=headers, json=body)\n",
    "  operation_location = submission.headers['Operation-Location']\n",
    "  retry_after = submission.headers['Retry-after']\n",
    "  status = \"\"\n",
    "  while (status != \"Succeeded\"):\n",
    "      time.sleep(int(retry_after))\n",
    "      response = requests.get(operation_location, headers=headers)\n",
    "      status = response.json()['status']\n",
    "  image_url = response.json()['result']['contentUrl']\n",
    "  #display(Image(url=image_url))\n",
    "  return \"\\n![image](\"+image_url+\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "229cbcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "![image](https://dalleproduse.blob.core.windows.net/private/images/edae749c-776e-4718-9584-1bab312886e4/generated_00.png?se=2023-09-11T14%3A03%3A27Z&sig=%2BvR8zFcwkP9VwJsjUuwo3hqHX650xvkOdp6vG4SNavQ%3D&ske=2023-09-15T12%3A03%3A23Z&skoid=09ba021e-c417-441c-b203-c81e5dcd7b7f&sks=b&skt=2023-09-08T12%3A03%3A23Z&sktid=33e01921-4d64-4f8c-a055-5bdaffd5e33d&skv=2020-10-02&sp=r&spr=https&sr=b&sv=2020-10-02)\n"
     ]
    }
   ],
   "source": [
    "print (create_image(\"A dog on the street.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6259befa",
   "metadata": {},
   "source": [
    "# 构建多模态Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73d3d329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_spotmax_doc(input):\n",
    "    print(input)\n",
    "    result = qa({\"query\": input})\n",
    "    return result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae415d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"SERPER_API_KEY\"] = \"\"\n",
    "# https://serper.dev\n",
    "from langchain.utilities import GoogleSerperAPIWrapper\n",
    "def query_web(question):\n",
    "    search = GoogleSerperAPIWrapper()\n",
    "    return search.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b51061bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, OpenAI, LLMChain\n",
    "from langchain.chains import LLMRequestsChain\n",
    "# from langchain.chat_models import ChatOpenAI #直接访问OpenAI的GPT服务\n",
    "\n",
    "#llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0) #直接访问OpenAI的GPT服务\n",
    "llm = AzureChatOpenAI(deployment_name = deployment, model_name=model, temperature=0.7, max_tokens=1000) #通过Azure的OpenAI服务\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4755e749",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, Tool\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Get current info\",func=query_web,\n",
    "        description=\"\"\"only invoke it when you need to answer questions about realtime info.\n",
    "             And the input should be a search query.\"\"\"),\n",
    "    Tool(\n",
    "        name=\"query spotmax doc\", func=query_spotmax_doc,\n",
    "        description=\"\"\"only invoke it when you need to get the info about spotmax/maxgroup/maxarch/maxchaos, \n",
    "        And the input should be the question.\"\"\"),\n",
    "    Tool(\n",
    "        name=\"create an image\", func=create_image,\n",
    "        description=\"\"\"invoke it when you need to create an image. \n",
    "        And the input should be the description of the image.\"\"\")\n",
    "]\n",
    "\n",
    "agent_chain = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", max_iterations=5,handle_parsing_errors=True,verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "baa87ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(input):\n",
    "    return agent_chain.run(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5defa47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The user is asking about the weather in Beijing today, which will affect what is appropriate to wear. I need real-time information to answer this, so I should use the 'Get current info' tool.\n",
      "Action: Get current info\n",
      "Action Input: Beijing weather today\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m71°F\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe weather in Beijing today is 71°F, which is fairly warm. Based on this, I can make a recommendation for what to wear.\n",
      "Final Answer: 今天在北京的天气大约是71°F，比较暖和。你可以穿短袖和短裤，但是也别忘了带一件薄外套，以防晚上变凉。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The user is asking for a visual representation of the clothing suggestion I provided. I should use the \"create an image\" tool to generate an image that fits the description.\n",
      "Action: create an image\n",
      "Action Input: A person wearing a short-sleeve shirt and shorts, with a light jacket draped over their arm.\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m\n",
      "![image](https://dalleproduse.blob.core.windows.net/private/images/23b979c0-354d-4d7b-aa49-d67a115a0521/generated_00.png?se=2023-09-11T14%3A10%3A12Z&sig=qB7swtVQ6jwFBOvNlSYMCcHh3t0Xljs6ExQAXUXkMH4%3D&ske=2023-09-16T12%3A43%3A34Z&skoid=09ba021e-c417-441c-b203-c81e5dcd7b7f&sks=b&skt=2023-09-09T12%3A43%3A34Z&sktid=33e01921-4d64-4f8c-a055-5bdaffd5e33d&skv=2020-10-02&sp=r&spr=https&sr=b&sv=2020-10-02)\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: Here is a visual representation of the clothing suggestion: ![image](https://dalleproduse.blob.core.windows.net/private/images/23b979c0-354d-4d7b-aa49-d67a115a0521/generated_00.png?se=2023-09-11T14%3A10%3A12Z&sig=qB7swtVQ6jwFBOvNlSYMCcHh3t0Xljs6ExQAXUXkMH4%3D&ske=2023-09-16T12%3A43%3A34Z&skoid=09ba021e-c417-441c-b203-c81e5dcd7b7f&sks=b&skt=2023-09-09T12%3A43%3A34Z&sktid=33e01921-4d64-4f8c-a055-5bdaffd5e33d&skv=2020-10-02&sp=r&spr=https&sr=b&sv=2020-10-02)\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "def respond(message, chat_history):\n",
    "    bot_message = get_response(message)\n",
    "    chat_history.append((message, bot_message))\n",
    "    return \"\", chat_history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(height=500) #just to fit the notebook\n",
    "    msg = gr.Textbox(label=\"Prompt\")\n",
    "    btn = gr.Button(\"Submit\")\n",
    "    clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "\n",
    "    btn.click(respond, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "    msg.submit(respond, inputs=[msg, chatbot], outputs=[msg, chatbot]) #Press enter to submit\n",
    "gr.close_all()\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37e415d",
   "metadata": {},
   "source": [
    "# 给Agent添加记忆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c41748c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
    "\n",
    "prefix = \"\"\"Have a conversation with a human, answering the following questions as best you can. You have access to the following tools:\"\"\"\n",
    "suffix = \"\"\"Begin!\"\n",
    "\n",
    "{chat_history}\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"],\n",
    ")\n",
    "memory = ConversationBufferWindowMemory(k=10, memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f6af5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True, handle_parsing_errors=True)\n",
    "agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent, tools=tools, verbose=True, memory=memory, handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "def get_response(input):\n",
    "    return agent_chain.run(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6e0a45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3c54ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
